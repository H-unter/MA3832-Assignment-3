{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832b4543-c435-4c20-abf4-972acc7a3378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T03:46:41.572537Z",
     "iopub.status.busy": "2025-08-14T03:46:41.571918Z",
     "iopub.status.idle": "2025-08-14T03:46:41.811147Z",
     "shell.execute_reply": "2025-08-14T03:46:41.810104Z",
     "shell.execute_reply.started": "2025-08-14T03:46:41.572504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.245.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import Session\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow as tf\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef827c86-fae9-4009-8752-518a4f19b9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T03:46:44.855713Z",
     "iopub.status.busy": "2025-08-14T03:46:44.854960Z",
     "iopub.status.idle": "2025-08-14T03:46:45.612371Z",
     "shell.execute_reply": "2025-08-14T03:46:45.611450Z",
     "shell.execute_reply.started": "2025-08-14T03:46:44.855680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: fsagemaker-ap-southeast-2-838084669510\n"
     ]
    }
   ],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()   # will be sagemaker-ap-southeast-2-838084669510\n",
    "prefix = \"aiornot\"\n",
    "print(f\"S3 Bucket: f{bucket}\")\n",
    "\n",
    "s3_small_train_path = f\"s3://{bucket}/{prefix}/small_train/small_train.npz\"\n",
    "s3_train_path = f\"s3://{bucket}/{prefix}/train/train.npz\"\n",
    "s3_test_path = f\"s3://{bucket}/{prefix}/test/test.npz\"\n",
    "\n",
    "small_train_input = TrainingInput(s3_small_train_path, content_type=\"application/x-npz\")\n",
    "train_input = TrainingInput(s3_train_path, content_type=\"application/x-npz\")\n",
    "test_input = TrainingInput(s3_test_path, content_type=\"application/x-npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f94014-1f2f-4021-a1f6-070f22186d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T04:53:54.583709Z",
     "iopub.status.busy": "2025-08-14T04:53:54.583293Z",
     "iopub.status.idle": "2025-08-14T05:01:30.397472Z",
     "shell.execute_reply": "2025-08-14T05:01:30.396421Z",
     "shell.execute_reply.started": "2025-08-14T04:53:54.583681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................!\n"
     ]
    }
   ],
   "source": [
    "estimator = tf(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",   # where train.py and model_def.py live\n",
    "    role=role,\n",
    "    # use_spot_instances=True,  # save money\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    framework_version=\"2.14\",\n",
    "    py_version=\"py310\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        \"height\": 512,\n",
    "        \"width\": 512,\n",
    "        \"channels\": 3,\n",
    "        \"model_dir\": \"/opt/ml/model\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Step 2: define search space\n",
    "hyperparameter_ranges = {\n",
    "    # numeric / continuous\n",
    "    \"learning-rate\": ContinuousParameter(1e-4, 1e-2, scaling_type=\"Logarithmic\"),\n",
    "    \"dropout-rate\": ContinuousParameter(0.0, 0.5),                 # if use-dropout=true\n",
    "    # integer choices for layer sizes\n",
    "    \"batch-size\": IntegerParameter(4, 8),                         # change range to suit memory\n",
    "    \"conv1-filters\": IntegerParameter(16, 128),\n",
    "    \"conv2-filters\": IntegerParameter(32, 256),\n",
    "    \"dense-units\": IntegerParameter(64, 512),\n",
    "    # categorical choices\n",
    "    \"pooling\": CategoricalParameter([\"max\", \"avg\"]),\n",
    "    \"use-dropout\": CategoricalParameter([\"true\", \"false\"]),\n",
    "}\n",
    "\n",
    "# Step 3: define regex to extract val_accuracy from train.py logs\n",
    "metric_definitions = [{\n",
    "    \"Name\": \"val_accuracy\",\n",
    "    \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"\n",
    "}]\n",
    "\n",
    "# Step 4: set up the tuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=\"val_accuracy\",\n",
    "    # strategy='Hyperband',\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=\"Maximize\",\n",
    "    early_stopping_type=\"Auto\",\n",
    "    max_jobs=1,\n",
    "    base_tuning_job_name=\"ph-12\"\n",
    ")\n",
    "\n",
    "# Step 5: launch it using small_train.npz for both train + val\n",
    "tuner.fit({\n",
    "    \"train\": small_train_input,\n",
    "    \"test\": test_input,\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

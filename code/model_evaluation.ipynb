{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef247ad-f0b7-4c73-a69f-3dc423687da0",
   "metadata": {},
   "source": [
    "note: ensure both endpoints are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ed5d8a-68a7-49ab-8922-a8c6aa78d0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T12:23:31.621177Z",
     "iopub.status.busy": "2025-08-16T12:23:31.620882Z",
     "iopub.status.idle": "2025-08-16T12:23:44.913963Z",
     "shell.execute_reply": "2025-08-16T12:23:44.913110Z",
     "shell.execute_reply.started": "2025-08-16T12:23:31.621150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 12:23:37.729102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: fsagemaker-ap-southeast-2-838084669510\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Session\n",
    "from sagemaker.session import TrainingInput\n",
    "from sagemaker.tensorflow import TensorFlow as tf\n",
    "from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import tensorflow\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "RANDOM_SEED = 0\n",
    "sagemaker.__version__\n",
    "fs = s3fs.S3FileSystem()\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket = sess.default_bucket()   # will be sagemaker-ap-southeast-2-838084669510\n",
    "prefix = \"aiornot\"\n",
    "print(f\"S3 Bucket: f{bucket}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd7750-8ba3-424f-941e-fe40d00cc2a6",
   "metadata": {},
   "source": [
    "# Start Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f93212-360a-490f-b0d5-cd430315ca35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T12:23:44.916338Z",
     "iopub.status.busy": "2025-08-16T12:23:44.915726Z",
     "iopub.status.idle": "2025-08-16T12:23:46.066687Z",
     "shell.execute_reply": "2025-08-16T12:23:46.065596Z",
     "shell.execute_reply.started": "2025-08-16T12:23:44.916311Z"
    }
   },
   "outputs": [],
   "source": [
    "transfer_model_s3_path = \"s3://sagemaker-ap-southeast-2-838084669510/model_output/transfer-learning-20250816-075841/output/model.tar.gz\"\n",
    "transfer_model = TensorFlowModel(\n",
    "    model_data=transfer_model_s3_path,\n",
    "    role=role,\n",
    "    framework_version=\"2.14\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    transfer_model_predictor = transfer_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        endpoint_name=\"transfer-model-endpoint\"\n",
    "    )\n",
    "except Exception: # has already been deployed, so just call the existing endpoint\n",
    "    transfer_model_predictor = TensorFlowPredictor(\n",
    "        endpoint_name=\"transfer-model-endpoint\",\n",
    "        sagemaker_session=sess\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa39bb05-6a71-4e19-9a45-93e2d87c928c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T12:23:46.069532Z",
     "iopub.status.busy": "2025-08-16T12:23:46.069035Z",
     "iopub.status.idle": "2025-08-16T12:23:47.355670Z",
     "shell.execute_reply": "2025-08-16T12:23:47.353891Z",
     "shell.execute_reply.started": "2025-08-16T12:23:46.069507Z"
    }
   },
   "outputs": [],
   "source": [
    "main_model_s3_path = \"s3://sagemaker-ap-southeast-2-838084669510/aiornot/model_output/bestparams-refit-20250816-094717/output/model.tar.gz\"\n",
    "main_model = TensorFlowModel(\n",
    "    model_data=main_model_s3_path,\n",
    "    role=role,\n",
    "    framework_version=\"2.14\"\n",
    ")\n",
    "try: # has not yet been deployed\n",
    "    main_model_predictor = main_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        endpoint_name=\"final-model-endpoint\"\n",
    "    )\n",
    "except Exception: # has already been deployed, so just call the existing endpoint\n",
    "    main_model_predictor = TensorFlowPredictor(\n",
    "        endpoint_name=\"final-model-endpoint\",\n",
    "        sagemaker_session=sess\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e033f0-a129-498d-8f94-709413cc90f7",
   "metadata": {},
   "source": [
    "# Make Predictions for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70fb7c-f188-4f82-9ca2-10612a8bf58e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-16T12:36:52.066Z",
     "iopub.execute_input": "2025-08-16T12:36:12.836600Z",
     "iopub.status.busy": "2025-08-16T12:36:12.835966Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = f\"s3://{bucket}/{prefix}/small_train/small_train.npz\"\n",
    "\n",
    "with fs.open(test_path, \"rb\") as f:\n",
    "    d = np.load(f)\n",
    "    X = d[\"image\"].astype(\"float32\") \n",
    "    y_true = np.asarray(d[\"label\"], dtype=int).ravel()\n",
    "    print(\"data loaded\")\n",
    "\n",
    "def predict_batches(pred, X, bs=1):\n",
    "    probs = []\n",
    "    for i in range(0, len(X), bs):\n",
    "        out = pred.predict(X[i:i+bs].tolist())\n",
    "        p = np.array(out.get(\"predictions\", out)).reshape(-1)  # shape (bs,)\n",
    "        probs.append(p)\n",
    "        print(f\"{i}/{len(X)}\")\n",
    "    probs = np.concatenate(probs)\n",
    "    predictions = (probs >= 0.5).astype(int)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "y_test_main_model = predict_batches(main_model_predictor, X)\n",
    "y_test_transfer_model = predict_batches(transfer_model_predictor, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

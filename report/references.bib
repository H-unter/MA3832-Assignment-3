@misc{huggingface_competitions_aiornot,
  author       = {{Hugging Face Datasets}},
  title        = {{competitions/aiornot}},
  year         = {2023},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/datasets/competitions/aiornot}},
  note         = {Accessed: 22 July 2025}
}

@online{scott2024ethics,
  author = {Chris Scott and others},
  title  = {Exploring the ethics of Artificial Intelligence in art},
  year   = {2024},
  date   = {2024-01-15},
  url    = {https://www.artshub.com.au/news/opinions-analysis/exploring-the-ethics-of-artificial-intelligence-in-art-2694121/},
  note   = {Accessed: 22 July 2025}
}

@misc{bird2023cifakeimageclassificationexplainable,
  title         = {CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images},
  author        = {Jordan J. Bird and Ahmad Lotfi},
  year          = {2023},
  eprint        = {2303.14126},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2303.14126}
}

@misc{lu2023seeingbelievingbenchmarkinghuman,
  title         = {Seeing is not always believing: Benchmarking Human and Model Perception of AI-Generated Images},
  author        = {Zeyu Lu and Di Huang and Lei Bai and Jingjing Qu and Chengyue Wu and Xihui Liu and Wanli Ouyang},
  year          = {2023},
  eprint        = {2304.13023},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2304.13023}
}

@online{keras_applications,
  author = {Keras Team},
  title  = {Keras Applications},
  year   = {2024},
  url    = {https://keras.io/api/applications/},
  note   = {Accessed: 22 July 2025}
}

@article{RAIAAN2024100470,
  title    = {A systematic review of hyperparameter optimization techniques in Convolutional Neural Networks},
  journal  = {Decision Analytics Journal},
  volume   = {11},
  pages    = {100470},
  year     = {2024},
  issn     = {2772-6622},
  doi      = {https://doi.org/10.1016/j.dajour.2024.100470},
  url      = {https://www.sciencedirect.com/science/article/pii/S2772662224000742},
  author   = {Mohaimenul Azam Khan Raiaan and Sadman Sakib and Nur Mohammad Fahad and Abdullah Al Mamun and Md. Anisur Rahman and Swakkhar Shatabda and Md. Saddam Hossain Mukta},
  keywords = {Convolutional Neural Network, Hyperparameter optimization Analysis, Optimizer, Activation function},
  abstract = {Convolutional Neural Network (CNN) is a prevalent topic in deep learning (DL) research for their architectural advantages. CNN relies heavily on hyperparameter configurations, and manually tuning these hyperparameters can be time-consuming for researchers, therefore we need efficient optimization techniques. In this systematic review, we explore a range of well used algorithms, including metaheuristic, statistical, sequential, and numerical approaches, to fine-tune CNN hyperparameters. Our research offers an exhaustive categorization of these hyperparameter optimization (HPO) algorithms and investigates the fundamental concepts of CNN, explaining the role of hyperparameters and their variants. Furthermore, an exhaustive literature review of HPO algorithms in CNN employing the above mentioned algorithms is undertaken. A comparative analysis is conducted based on their HPO strategies, error evaluation approaches, and accuracy results across various datasets to assess the efficacy of these methods. In addition to addressing current challenges in HPO, our research illuminates unresolved issues in the field. By providing insightful evaluations of the merits and demerits of various HPO algorithms, our objective is to assist researchers in determining a suitable method for a particular problem and dataset. By highlighting future research directions and synthesizing diversified knowledge, our survey contributes significantly to the ongoing development of CNN hyperparameter optimization.}
}